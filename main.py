import os
import logging
from telegram import Update
from telegram.ext import Updater, CommandHandler, MessageHandler, Filters, CallbackContext

# å¯¼å…¥AIå¼€å‘åŒ…
import google.generativeai as genai
from PIL import Image

# è®¾ç½®æ—¥å¿—
logging.basicConfig(
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s', level=logging.INFO
)
logger = logging.getLogger(__name__)


# --- æœºå™¨äººä¸“å®¶äººè®¾ (ä¸­æ–‡ç‰ˆ) ---
EXPERT_PERSONA_PROMPT_ZH = (
    "ä½ æ˜¯ä¸€ä½åä¸º'CBH AIäº¤æ˜“ä¸“å®¶'çš„èµ„æ·±AIåŠ©æ‰‹ï¼Œç²¾é€šå¤–æ±‡äº¤æ˜“é¢†åŸŸã€‚ä½ æ€»æ˜¯ä»¥ä¸“ä¸šã€è‡ªä¿¡ä¸”ä¹äºåŠ©äººçš„å£å»ï¼Œ"
    "æä¾›å¯Œæœ‰æ´å¯ŸåŠ›çš„åˆ†æï¼Œè§£é‡Šäº¤æ˜“ç­–ç•¥ï¼Œå¹¶æ¢è®¨å¸‚åœºè¶‹åŠ¿ã€‚"
    "é‡è¦æç¤ºï¼šåœ¨ä½ çš„æ¯ä¸€æ¡å›å¤çš„ç»“å°¾ï¼Œéƒ½å¿…é¡»å¦èµ·ä¸€è¡Œé™„ä¸Šä»¥ä¸‹å…è´£å£°æ˜ï¼š"
    "--- \n*å…è´£å£°æ˜ï¼šæˆ‘æ˜¯ä¸€ä¸ªAIåŠ©æ‰‹ã€‚æ‰€æœ‰å†…å®¹ä¸æ„æˆè´¢åŠ¡å»ºè®®ï¼Œæ‰€æœ‰äº¤æ˜“å‡æ¶‰åŠé£é™©ã€‚*"
)

# --- ç»Ÿä¸€ä½¿ç”¨æœ€æ–°çš„AIæ¨¡å‹ ---
# gemini-1.5-flash æ˜¯ä¸€ä¸ªå¼ºå¤§çš„å¤šæ¨¡æ€æ¨¡å‹ï¼Œå¯ä»¥åŒæ—¶å¤„ç†æ–‡æœ¬å’Œå›¾ç‰‡
AI_MODEL_NAME = 'gemini-1.5-flash'


# --- AIè§†è§‰ä¸èŠå¤©åŠŸèƒ½ ---

def analyze_chart_with_gemini(image_path: str) -> str:
    logger.info(f"æ­£åœ¨ä½¿ç”¨æ¨¡å‹ {AI_MODEL_NAME} åˆ†æå›¾è¡¨...")
    api_key = os.getenv("GOOGLE_API_KEY")
    if not api_key:
        logger.error("ç¯å¢ƒå˜é‡ GOOGLE_API_KEY æœªè®¾ç½®ï¼")
        return "é”™è¯¯ï¼šæœåŠ¡å™¨ç«¯çš„AIåˆ†æåŠŸèƒ½æœªé…ç½®ã€‚"

    try:
        genai.configure(api_key=api_key)
        # ä½¿ç”¨æ›´æ–°åçš„æ¨¡å‹åç§°
        model = genai.GenerativeModel(AI_MODEL_NAME)
        img = Image.open(image_path)
        
        prompt = (
            f"{EXPERT_PERSONA_PROMPT_ZH}\n\n"
            "ç°åœ¨ï¼Œè¯·ä¸“é—¨åˆ†æé™„ä¸Šçš„è¿™å¼ é‡‘èå›¾è¡¨ã€‚è¯·ä»…æ ¹æ®å›¾ä¸­çš„è§†è§‰ä¿¡æ¯ï¼ˆå¦‚Kçº¿ã€è¶‹åŠ¿çº¿ã€æŒ‡æ ‡ç­‰ï¼‰ï¼Œ"
            "ç»™å‡ºä¸€ä¸ªæ¸…æ™°çš„äº¤æ˜“å»ºè®®ï¼ˆä¹°å…¥ã€å–å‡º æˆ– è§‚æœ›ï¼‰ï¼Œå¹¶é™„ä¸Šç®€çŸ­çš„ç†ç”±ã€‚"
        )
        
        response = model.generate_content([prompt, img])
        analysis_result = response.text
        logger.info(f"ä»Geminiæ”¶åˆ°çš„åˆ†æç»“æœ: {analysis_result}")
        return analysis_result

    except Exception as e:
        logger.error(f"è°ƒç”¨Gemini APIæ—¶å‡ºé”™: {e}")
        # è¿”å›æ›´è¯¦ç»†çš„é”™è¯¯ç»™ç”¨æˆ·ï¼Œæ–¹ä¾¿è°ƒè¯•
        return f"æŠ±æ­‰ï¼ŒAIåˆ†æå¸ˆå½“å‰ä¸å¯ç”¨ã€‚é”™è¯¯: {e}"


def chat_with_gemini(user_text: str) -> str:
    logger.info(f"æ­£åœ¨ä½¿ç”¨æ¨¡å‹ {AI_MODEL_NAME} å¤„ç†æ–‡å­—é—®é¢˜: '{user_text}'")
    api_key = os.getenv("GOOGLE_API_KEY")
    if not api_key:
        return "é”™è¯¯ï¼šAIèŠå¤©åŠŸèƒ½æœªé…ç½®ã€‚"

    try:
        genai.configure(api_key=api_key)
        # åŒæ ·ä½¿ç”¨æ›´æ–°åçš„æ¨¡å‹åç§°
        model = genai.GenerativeModel(AI_MODEL_NAME)
        
        full_prompt = f"{EXPERT_PERSONA_PROMPT_ZH}\n\nç”¨æˆ·çš„é—®é¢˜æ˜¯ï¼š'{user_text}'"

        response = model.generate_content(full_prompt)
        chat_reply = response.text
        logger.info(f"ä»Geminiæ”¶åˆ°çš„èŠå¤©å›å¤: {chat_reply}")
        return chat_reply

    except Exception as e:
        logger.error(f"è°ƒç”¨Gemini APIæ—¶å‡ºé”™: {e}")
        return f"æŠ±æ­‰ï¼Œæˆ‘çš„AIå¤§è„‘æš‚æ—¶æ— æ³•è¿æ¥ã€‚é”™è¯¯: {e}"


# --- Telegramæœºå™¨äººå¤„ç†å™¨ (æ— éœ€æ”¹åŠ¨) ---

def start(update: Update, context: CallbackContext) -> None:
    update.message.reply_text(
        "æ¬¢è¿ä½¿ç”¨ CBH AI äº¤æ˜“ä¸“å®¶ï¼\n\n"
        "ä½œä¸ºä¸€åä¸“ä¸šçš„AIäº¤æ˜“åŠ©æ‰‹ï¼Œæˆ‘å¯ä»¥ï¼š\n"
        "ğŸ“ˆ **åˆ†æå›¾è¡¨**ï¼šå‘é€ä»»ä½•äº¤æ˜“å›¾è¡¨ç…§ç‰‡ç»™æˆ‘ã€‚\n"
        "ğŸ’¬ **æ¢è®¨ç­–ç•¥**ï¼šå‘æˆ‘è¯¢é—®ä»»ä½•å…³äºå¤–æ±‡ã€äº¤æ˜“ç­–ç•¥æˆ–å¸‚åœºåˆ†æçš„é—®é¢˜ã€‚\n\n"
        "ä»Šå¤©æˆ‘èƒ½å¦‚ä½•ååŠ©æ‚¨ï¼Ÿ"
    )

def handle_photo(update: Update, context: CallbackContext) -> None:
    reply = update.message.reply_text("ğŸ“ˆ å·²æ”¶åˆ°å›¾è¡¨ã€‚æ­£åœ¨ç”¨æˆ‘çš„AIè§†è§‰è¿›è¡Œåˆ†æï¼Œè¯·ç¨å€™...", quote=True)
    photo_file = update.message.photo[-1].get_file()
    temp_photo_path = f"{photo_file.file_id}.jpg"
    photo_file.download(temp_photo_path)
    analysis_result = analyze_chart_with_gemini(temp_photo_path)
    reply.edit_text(analysis_result, parse_mode='Markdown')
    os.remove(temp_photo_path)

def handle_text(update: Update, context: CallbackContext) -> None:
    user_message = update.message.text
    reply = update.message.reply_text("ğŸ’¬ æ­£åœ¨æ€è€ƒä¸­...", quote=True)
    ai_response = chat_with_gemini(user_message)
    reply.edit_text(ai_response, parse_mode='Markdown')

def main() -> None:
    bot_token = os.getenv("BOT_TOKEN")
    if not bot_token:
        logger.critical("è‡´å‘½é”™è¯¯: ç¯å¢ƒå˜é‡ BOT_TOKEN æœªè®¾ç½®ï¼")
        return

    updater = Updater(bot_token, use_context=True)
    dispatcher = updater.dispatcher

    dispatcher.add_handler(CommandHandler("start", start))
    dispatcher.add_handler(MessageHandler(Filters.photo, handle_photo))
    dispatcher.add_handler(MessageHandler(Filters.text & ~Filters.command, handle_text))

    updater.start_polling()
    logger.info("CBH AI äº¤æ˜“ä¸“å®¶æœºå™¨äººå·²æˆåŠŸå¯åŠ¨ï¼")
    updater.idle()


if __name__ == '__main__':
    main()
